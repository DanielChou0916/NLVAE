{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot()\nplt.close()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torchvision import transforms, models\nfrom tqdm import tqdm\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch.distributions as dist\nimport os\nfrom density_estimation import *\nfrom nonlinear_vae import *\nfrom custom_data_loading import *\nfrom train_vae import *\nfrom distance_correlation import *\nfrom spearman_correlation import *","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor_path='/kaggle/input/0618-mixed-stress-path'\n#tensor_path='/kaggle/input/scaled-stress-with-channel-regarding2dataset/Set3'\nfile_list=[]\nfor dirname, _, filenames in os.walk(tensor_path):\n    for filename in filenames:\n        file_list.append(os.path.join(dirname, filename))\nprint('The data set size:',len(file_list))\n#Remove the initial state\nimport re\nfor i in file_list:\n#j=0\n    pt_name=i.split('\\\\')[-1]\n    if re.findall(r'\\d+', pt_name)[-1]=='0':\n        file_list.remove(i)\nprint('The data set size:',len(file_list))\n\ntrain_list,test_list=list_splitting(file_list,proportion=0.2,shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor_path='/kaggle/input/0618-mixed-stress-path'\n#tensor_path='/kaggle/input/scaled-stress-with-channel-regarding2dataset/Set3'\nfile_list=[]\nfor dirname, _, filenames in os.walk(tensor_path):\n    for filename in filenames:\n        file_list.append(os.path.join(dirname, filename))\nprint('The data set size:',len(file_list))\n#Remove the initial state\nimport re\nfor i in file_list:\n#j=0\n    pt_name=i.split('\\\\')[-1]\n    if re.findall(r'\\d+', pt_name)[-1]=='0':\n        file_list.remove(i)\nprint('The data set size:',len(file_list))\n\ntrain_list,test_list=list_splitting(file_list,proportion=0.2,shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\nparam={'lr':0.00001,\n       'max_epoch':125,\n       'batch_sz':32,\n       'Type':'Covariance',\n       'beta':0,\n       'alpha':0,\n       'l1':0,\n       'l2':10,\n       'l3':10,\n       'by_channel':True,\n       'channel_idx':0,\n       'normalize':False,\n       'loss_fn':elbo_loss_SC,\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"M=NonLinearVAE(fc_list=[256*25*25,1024,521,128,64,32])\nM.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_M=VAE_list_trainer(M,train_list,test_list,param)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_reg_VAE(trained_M,mode='Training_only')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=load_a_batch_tensor(train_list[:32],by_channel=True).to(device)\n_,z,x_hat=M.forward(x)\ni=1\nplt.matshow(x[i,0].cpu().detach().numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.matshow(x_hat[i,0].cpu().detach().numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile = {'Trained_model':trained_M,\\\n            'Trained_param':param,\\\n           'state_dict': trained_M.state_dict(),}\ntorch.save(profile,'0626_SkVAE_SP_zShape32.pth')","metadata":{},"execution_count":null,"outputs":[]}]}