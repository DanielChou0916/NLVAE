{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3798c80",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-27T18:12:46.399711Z",
     "iopub.status.busy": "2023-06-27T18:12:46.399372Z",
     "iopub.status.idle": "2023-06-27T18:12:50.286095Z",
     "shell.execute_reply": "2023-06-27T18:12:50.284388Z"
    },
    "papermill": {
     "duration": 3.892603,
     "end_time": "2023-06-27T18:12:50.288890",
     "exception": false,
     "start_time": "2023-06-27T18:12:46.396287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, models\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "import os\n",
    "import re\n",
    "\n",
    "def batch_tensor_standardization(batch_data):\n",
    "    # Assume 'batch_data' is the batch of stress maps with shape (batch_size, 1, 100, 100)\n",
    "    # Compute mean and standard deviation for each stress map\n",
    "    mean = torch.mean(batch_data, dim=(2, 3), keepdim=True)\n",
    "    std = torch.std(batch_data, dim=(2, 3), keepdim=True)\n",
    "\n",
    "    # Normalize each stress map individually\n",
    "    normalized_data = (batch_data - mean) / (std+ 1e-6)\n",
    "    return normalized_data,mean,std\n",
    "\n",
    "def report_tensor_list(tensor_path):\n",
    "    \n",
    "    #UC_path='/kaggle/input/mixed-stress-path/Set_III_UCTensors'\n",
    "    #tensor_path='/kaggle/input/scaled-stress-with-channel-regarding2dataset/Set3'\n",
    "    file_list=[]\n",
    "    for dirname, _, filenames in os.walk(tensor_path):\n",
    "        for filename in filenames:\n",
    "            file_list.append(os.path.join(dirname, filename))\n",
    "    #print('The data set size:',len(file_list))\n",
    "    #Remove the initial state\n",
    "\n",
    "    for i in file_list:\n",
    "    #j=0\n",
    "        pt_name=i.split('\\\\')[-1]\n",
    "        if re.findall(r'\\d+', pt_name)[-1]=='0':\n",
    "            file_list.remove(i)\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def list_splitting(target_list,proportion=0.2,shuffle=True):\n",
    "    if shuffle:\n",
    "        random.shuffle(target_list)\n",
    "    split_idx=int((1-proportion)*len(target_list))\n",
    "    tarin_list=target_list[:split_idx]\n",
    "    test_list=target_list[split_idx:]\n",
    "    return tarin_list,test_list\n",
    "\n",
    "def max_min_norm(a):\n",
    "    return (a-a.min())/(a.max()-a.min())\n",
    "\n",
    "\n",
    "def load_a_batch_tensor(sub_file_list,by_channel=False,channel_idx=0):\n",
    "    '''\n",
    "    This function is designed to load the batch tensor from a list\n",
    "    1. The batch size=len(sub_file_list)\n",
    "    2. by_channel: boolean param used to specify weather to just load the channels\n",
    "                   E.g., only want to use specific stress components to train the model.\n",
    "    3. channel_idx: which channel we want to use. Can be a single int or a list.\n",
    "    '''\n",
    "    try:\n",
    "        assert type(sub_file_list) == list\n",
    "    except:\n",
    "        sub_file_list=[sub_file_list]\n",
    "    batch_tensor=torch.tensor([])\n",
    "    if not by_channel:\n",
    "        for tensor in sub_file_list:\n",
    "            stress=torch.load(tensor).unsqueeze(0)\n",
    "            batch_tensor=torch.cat([batch_tensor,stress])\n",
    "    else:\n",
    "        for tensor in sub_file_list:\n",
    "            stress=torch.load(tensor)#.unsqueeze(0)\n",
    "            stress=stress[channel_idx,:,:].unsqueeze(0).unsqueeze(0)\n",
    "            batch_tensor=torch.cat([batch_tensor,stress])\n",
    "    #if load channels by a list, the dim will be 5, so squeeze the extra dim.\n",
    "    #Since one of the unsqueeze operation in 'else:' is redundant \n",
    "    if len(batch_tensor.shape)>4:\n",
    "        batch_tensor=batch_tensor.squeeze(1)\n",
    "    return batch_tensor.type('torch.FloatTensor')\n",
    "\n",
    "#0426 VAE_cov\n",
    "def diagonal_decomposition(M):\n",
    "    off_diag = M.clone()\n",
    "    off_diag.diagonal(dim1=-1, dim2=-2).zero_()\n",
    "    diag=M.clone()\n",
    "    diag=diag.diagonal(dim1=-1, dim2=-2)\n",
    "    return diag,off_diag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.954577,
   "end_time": "2023-06-27T18:12:51.615168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-27T18:12:35.660591",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
