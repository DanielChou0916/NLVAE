{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139ef34a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-26T12:15:35.499400Z",
     "iopub.status.busy": "2023-06-26T12:15:35.498886Z",
     "iopub.status.idle": "2023-06-26T12:15:39.097043Z",
     "shell.execute_reply": "2023-06-26T12:15:39.095934Z"
    },
    "papermill": {
     "duration": 3.605292,
     "end_time": "2023-06-26T12:15:39.099785",
     "exception": false,
     "start_time": "2023-06-26T12:15:35.494493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "#from torch import nn, optim\n",
    "#from torchvision import transforms, models\n",
    "#import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "\n",
    "#def ensure_positive_definite(covariance):\n",
    "#    eigenvalues, eigenvectors = torch.linalg.eigh(covariance)\n",
    "#    eigenvalues = torch.clamp(eigenvalues, min=1e-6)  # Set small eigenvalues to a minimum positive value\n",
    "#    covariance = torch.mm(torch.mm(eigenvectors, torch.diag(eigenvalues)), eigenvectors.T)\n",
    "#    return covariance\n",
    "def ensure_positive_definite(matrix, eps=1e-4):\n",
    "    # Perform eigen decomposition\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(matrix)\n",
    "    \n",
    "    # Ensure all eigenvalues are positive\n",
    "    positive_eigenvalues = torch.clamp(eigenvalues, min=eps)\n",
    "    \n",
    "    # Reconstruct the matrix with modified eigenvalues\n",
    "    positive_definite_matrix = torch.matmul(\n",
    "        eigenvectors, torch.matmul(torch.diag(positive_eigenvalues), eigenvectors.T)\n",
    "    )\n",
    "    \n",
    "    return positive_definite_matrix\n",
    "\n",
    "# Example usage:\n",
    "#covariance = torch.rand(32, 32)  # Replace with your covariance matrix\n",
    "#positive_definite_covariance = ensure_positive_definite(covariance)\n",
    "\n",
    "def multi_vars_SkewNormal_density_estimate(values,check=False):\n",
    "    '''\n",
    "    Estimate the probability density by SkewNormal density function\n",
    "    Input: A 2D tensor contains n samples and d features\n",
    "    check: Used to visualize the density estimation in smooth curve\n",
    "    '''\n",
    "    mean = torch.mean(values,0)\n",
    "    std = torch.std(values,0)\n",
    "    skewness = torch.mean((values - mean) ** 3,0) / torch.pow(std, 3)\n",
    "    residuals = values - mean\n",
    "    standard_normal = dist.Normal(0, 1)\n",
    "    kernel_values = 2 * standard_normal.cdf((residuals / std) *skewness) *(1/(std*(2*torch.pi)**0.5))* torch.exp(-0.5 * (residuals / std).pow(2))\n",
    "    pdf = kernel_values / (torch.sum(kernel_values,0))\n",
    "    #Check\n",
    "    if check:\n",
    "        bins=torch.tensor(np.linspace((values.min(0).values),(values.max(0).values),100))\n",
    "        r_check=bins-mean\n",
    "        k_check=2 * standard_normal.cdf((r_check / std) * skewness) *(1/(std*(2*torch.pi)**0.5))* torch.exp(-0.5 * (residuals / std).pow(2))\n",
    "        pdf_check=k_check / (torch.sum(k_check,0))\n",
    "        return pdf,kernel_values,[bins,k_check,pdf_check]\n",
    "    else: \n",
    "        return pdf,kernel_values\n",
    "\n",
    "def estimate_total_joint_density_skew_normal_training(values):\n",
    "    mean = torch.mean(values, dim=0)\n",
    "    residuals = values - mean\n",
    "    covariance = torch.cov(residuals.T)\n",
    "    skewness = torch.mean((residuals) ** 3, dim=0) / torch.pow((torch.diagonal(covariance))**0.5, 3)\n",
    "\n",
    "    standard_normal = dist.Normal(0, 1)\n",
    "    #cdf term\n",
    "    cdf=standard_normal.cdf((residuals/torch.diagonal(covariance).sqrt())@ (skewness.unsqueeze(0)).T)\n",
    "    #phi(x) term\n",
    "    try:\n",
    "        multinormal=dist.MultivariateNormal(mean, covariance)\n",
    "    except:\n",
    "        covariance=ensure_positive_definite(covariance)\n",
    "        multinormal=dist.MultivariateNormal(mean, covariance)\n",
    "    pd=multinormal.log_prob(values).exp()\n",
    "\n",
    "    jointskewtotal=2*pd.reshape(cdf.shape)*cdf\n",
    "    nor_joint=jointskewtotal/(jointskewtotal.sum())\n",
    "    return nor_joint,jointskewtotal\n",
    "\n",
    "def estimate_total_joint_density_skew_normal(values,mean,covariance,skewness):\n",
    "    #mean = torch.mean(values, dim=0)\n",
    "    residuals = values - mean\n",
    "    #covariance = torch.cov(residuals.T)\n",
    "    #skewness = torch.mean((residuals) ** 3, dim=0) / torch.pow((torch.diagonal(covariance))**0.5, 3)\n",
    "\n",
    "    standard_normal = dist.Normal(0, 1)\n",
    "    #cdf term\n",
    "    cdf=standard_normal.cdf((residuals/torch.diagonal(covariance).sqrt())@ (skewness.unsqueeze(0)).T)\n",
    "    #phi(x) term\n",
    "    try:\n",
    "        multinormal=dist.MultivariateNormal(mean, covariance)\n",
    "    except:\n",
    "        covariance=ensure_positive_definite(covariance)\n",
    "        multinormal=dist.MultivariateNormal(mean, covariance)\n",
    "    pd=multinormal.log_prob(values).exp()\n",
    "\n",
    "    jointskewtotal=2*pd.reshape(cdf.shape)*cdf\n",
    "    nor_joint=jointskewtotal/(jointskewtotal.sum())\n",
    "    return nor_joint,jointskewtotal\n",
    "\n",
    "\n",
    "\n",
    "def estimate_total_joint_density(data):\n",
    "    # Calculate the mean and covariance of the data\n",
    "    mean = torch.mean(data, dim=0)\n",
    "    covariance = torch.cov(data.T)\n",
    "    try:\n",
    "        multinormal=dist.MultivariateNormal(mean, covariance)\n",
    "    except:\n",
    "        covariance=ensure_positive_definite(covariance)\n",
    "        multinormal=dist.MultivariateNormal(mean, covariance)\n",
    "\n",
    "    # Evaluate the log probability density at the data points\n",
    "    log_density = multinormal.log_prob(data)\n",
    "\n",
    "    # Convert log density to tensor\n",
    "    log_density_tensor = log_density.reshape(-1,1)#.detach()\n",
    "\n",
    "    # Reshape the density tensor to match the input data shape\n",
    "    joint_density = torch.exp(log_density_tensor)#.reshape(data.shape)\n",
    "    nor_joint=joint_density/(joint_density.sum())\n",
    "    return nor_joint, joint_density\n",
    "\n",
    "def total_correlation_estimation(marginal,joint,weight_sum=True):\n",
    "    eps=1e-6\n",
    "    joint_log=torch.log(joint+eps)\n",
    "    marginal_log = torch.log(marginal+eps)\n",
    "    marginal_log_sum=marginal_log.sum(dim=1,keepdim=True)\n",
    "    if weight_sum:\n",
    "        total_corr = joint*(joint_log - marginal_log_sum)\n",
    "    else:\n",
    "        total_corr = (joint_log - marginal_log_sum)\n",
    "    return total_corr\n",
    "\n",
    "def pair_wise_MI_upper(z,full_cov=False):\n",
    "    '''\n",
    "    Input, z in (n,d)\n",
    "    Output, mi_upper array, abs sum of array\n",
    "    '''\n",
    "    _,d=z.size()\n",
    "    mi_upper=torch.zeros(d,d).to(z.device)\n",
    "    _,marginal_kernel=multi_vars_SkewNormal_density_estimate(z)\n",
    "    if full_cov:\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                marginal_kernel_=marginal_kernel[:,[i,j]]\n",
    "                _,joint_kernel=estimate_total_joint_density_skew_normal_training(z[:,[i,j]])\n",
    "                mi=total_correlation_estimation(marginal_kernel_,joint_kernel).sum()\n",
    "                mi_upper[i,j]=mi\n",
    "    else:        \n",
    "        for i in range(d):\n",
    "            for j in range(i+1,d):\n",
    "                marginal_kernel_=marginal_kernel[:,[i,j]]\n",
    "                _,joint_kernel=estimate_total_joint_density_skew_normal_training(z[:,[i,j]])\n",
    "                mi=total_correlation_estimation(marginal_kernel_,joint_kernel).sum()\n",
    "                mi_upper[i,j]=mi\n",
    "    return mi_upper, mi_upper.abs().sum()\n",
    "#_,mi_sum=pair_wise_MI_upper(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.136096,
   "end_time": "2023-06-26T12:15:40.830264",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-26T12:15:24.694168",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
