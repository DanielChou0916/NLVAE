{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93288047",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-27T13:38:30.953259Z",
     "iopub.status.busy": "2023-06-27T13:38:30.952799Z",
     "iopub.status.idle": "2023-06-27T13:38:35.951271Z",
     "shell.execute_reply": "2023-06-27T13:38:35.949422Z"
    },
    "papermill": {
     "duration": 5.006632,
     "end_time": "2023-06-27T13:38:35.954241",
     "exception": false,
     "start_time": "2023-06-27T13:38:30.947609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "class NonLinearVAE(nn.Module):\n",
    "    def __init__(self,input_channel=1,Leaky=1.02,fc_list=[128*25*25,1024,521,128,32,16],ptype='Skew',component=3):\n",
    "        \"\"\"\n",
    "        0424 Deeper channel VAE\n",
    "        \"\"\"\n",
    "        super(NonLinearVAE,self).__init__()\n",
    "        self.input_channel=input_channel\n",
    "        self.Leaky=Leaky\n",
    "        self.fc_layer_num_list=fc_list\n",
    "        self.ptype=ptype\n",
    "        self.component=component\n",
    "        self.Encoder_generating()\n",
    "        self.Decoder_generating()\n",
    "\n",
    "    def Encoder_generating(self):\n",
    "        \"\"\"\n",
    "        Manually assign the structure of encoder for each layer\n",
    "        \"\"\"\n",
    "        Encoder_CNN=nn.Sequential(\n",
    "                        nn.Conv2d(self.input_channel, 16, 3, stride=1, padding=1),\\\n",
    "                        nn.LeakyReLU(self.Leaky),\\\n",
    "                        nn.Conv2d(16, 32, 3, stride=1, padding=1),\\\n",
    "                        nn.LeakyReLU(self.Leaky),\\\n",
    "                        nn.Conv2d(32, 64, 3, stride=1, padding=1),\\\n",
    "                        nn.LeakyReLU(self.Leaky),\\\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\\\n",
    "                        nn.Conv2d(64, 128, 3, stride=1, padding=1),\\\n",
    "                        #nn.BatchNorm2d(256),\n",
    "                        nn.Tanhshrink(),\\\n",
    "                        nn.Conv2d(128, 128, 3, stride=1, padding=1),\\\n",
    "                        nn.Tanhshrink(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                        )\n",
    "        #Encoder FC\n",
    "        #Heaver option\n",
    "        encoder_4_VAE_list=self.fc_layer_num_list.copy()\n",
    "        if self.ptype=='GMM':\n",
    "            print('You are using GM-VAE')\n",
    "            encoder_4_VAE_list[-1]=(3*self.component)*encoder_4_VAE_list[-1]\n",
    "        else:\n",
    "            print('You are using SkewNormal-VAE')\n",
    "            encoder_4_VAE_list[-1]=3*encoder_4_VAE_list[-1]\n",
    "        Encoder_fc=nn.Sequential()\n",
    "        for idx,i in enumerate(encoder_4_VAE_list):\n",
    "            if idx+1!= len(encoder_4_VAE_list):\n",
    "                Encoder_fc.add_module(str(idx),nn.Linear(i,encoder_4_VAE_list[idx+1]))\n",
    "                Encoder_fc.add_module('Activate'+str(idx),nn.LeakyReLU(self.Leaky))\n",
    "        self.Encoder_CNN=Encoder_CNN\n",
    "        self.Encoder_fc=Encoder_fc\n",
    "\n",
    "    def Decoder_generating(self):\n",
    "        Decoder_CNN=nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Tanhshrink(),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.Conv2d(128, 128, 3, stride=1, padding=1,dilation=1),\n",
    "                nn.Tanhshrink(),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.Conv2d(128,64, 3, stride=1, padding=1,dilation=1),\n",
    "                nn.LeakyReLU(self.Leaky),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(64, 32, 3, stride=1, padding=1,dilation=1),\n",
    "                nn.LeakyReLU(self.Leaky),\n",
    "                nn.Conv2d(32, 16, 3, stride=1, padding=1,dilation=1),\n",
    "                nn.LeakyReLU(self.Leaky),\n",
    "                nn.Conv2d(16, self.input_channel, 3, stride=1, padding=1,dilation=1),\n",
    "                )\n",
    "        self.Decoder_CNN=Decoder_CNN\n",
    "        #Decoder FC\n",
    "        Decoder_fc=nn.Sequential()\n",
    "        j=0\n",
    "        for i in range(len(self.fc_layer_num_list)-1,-1,-1):\n",
    "            if (i==1):#|(i==2):\n",
    "                Decoder_fc.add_module(str(j),nn.Linear(self.fc_layer_num_list[i],self.fc_layer_num_list[i-1]))\n",
    "                Decoder_fc.add_module('Activate'+str(j),nn.Tanhshrink())                \n",
    "            elif i != 0:\n",
    "                Decoder_fc.add_module(str(j),nn.Linear(self.fc_layer_num_list[i],self.fc_layer_num_list[i-1]))\n",
    "                Decoder_fc.add_module('Activate'+str(j),nn.LeakyReLU(self.Leaky))\n",
    "                Decoder_fc.add_module('BatchNorm'+str(j),nn.BatchNorm1d(self.fc_layer_num_list[i-1]))\n",
    "            j+=1\n",
    "        self.Decoder_fc=Decoder_fc\n",
    "    def forward_encoder(self,X):\n",
    "        '''\n",
    "        X: the 4D image tensor\n",
    "        '''\n",
    "        #Forward of encoder\n",
    "        out=self.Encoder_CNN(X)\n",
    "        out=self.Encoder_fc(out.view(out.size(0),-1))\n",
    "        if self.ptype=='GMM': #Incase of GMM\n",
    "            # Assuming batch size of 8, GMM with 3 components, and 32-dimensional latent vector\n",
    "            encoder_output = out.reshape(len(X), self.component, 3, self.fc_layer_num_list[-1])  \n",
    "            # Chunk the encoder output into mixture weights, means, and standard deviations\n",
    "            weights, means, log_var = torch.chunk(encoder_output, chunks=3, dim=2)\n",
    "            # Apply softmax to the weights\n",
    "            weights = F.softmax(weights, dim=1)\n",
    "            # Apply softplus to the standard deviations\n",
    "            stds = torch.exp(0.5 * log_var)\n",
    "            stds = F.softplus(stds)\n",
    "            # Reshape the chunks if needed\n",
    "            weights = weights.squeeze(2)  # Shape: (8, 3, 32)\n",
    "            means = means.squeeze(2)  # Shape: (8, 3, 32)\n",
    "            stds = stds.squeeze(2)  # Shape: (8, 3, 32)\n",
    "            # Apply the reparametrization trick with GMM\n",
    "            epsilon = torch.randn_like(stds).to(stds.device)  # Sample from a standard normal distribution\n",
    "            z = torch.sum(weights * (means + stds * epsilon), dim=1)\n",
    "            #print('GMM process')\n",
    "            return means,stds,weights,z\n",
    "        else:#In case of the skew-normal\n",
    "            #Split to mean and standard deviation\n",
    "            mean,log_var,alp=torch.chunk(out,3,1)\n",
    "            stds = torch.exp(0.5 * log_var)\n",
    "            stds = F.softplus(stds)#The softplus should be added here!\n",
    "            epsilon=torch.randn_like(log_var).to(stds.device)\n",
    "            z=mean+stds*epsilon+alp*torch.abs(epsilon)\n",
    "            #print('Skew-normal process')\n",
    "            return mean,stds,alp,z\n",
    "    def forward(self,X):\n",
    "        if self.ptype=='GMM':\n",
    "            #print('GM forward')\n",
    "            means,stds,weights,z=self.forward_encoder(X)\n",
    "            X_hat=self.Decoder_CNN(self.Decoder_fc(z).reshape(-1,128,25,25))\n",
    "            return [means,stds,weights],z,X_hat\n",
    "        else:\n",
    "            #print('Skew forward')\n",
    "            mean,stds,alp,z=self.forward_encoder(X)\n",
    "            X_hat=self.Decoder_CNN(self.Decoder_fc(z).reshape(-1,128,25,25))\n",
    "            return [mean,stds,alp],z,X_hat\n",
    "    \n",
    "    def forward_decoder(self,z):\n",
    "        return self.Decoder_CNN(self.Decoder_fc(z).reshape(-1,128,25,25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.534051,
   "end_time": "2023-06-27T13:38:37.687616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-27T13:38:19.153565",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
